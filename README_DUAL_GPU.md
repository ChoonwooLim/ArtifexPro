# ğŸš€ ArtifexPro Dual GPU Setup Guide

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
- **Windows PC**: RTX 3090 (24GB) - Frontend + Ray Worker
- **Pop!_OS PC**: RTX 3090 (24GB) - Backend + Ray Head
- **Total VRAM**: 48GB (ë¶„ì‚° ì²˜ë¦¬)
- **Connection**: 10GbE Direct or LAN

## ğŸ¯ Quick Start

### 1. ì „ì²´ ì‹œìŠ¤í…œ ì‹œì‘
```powershell
# Windowsì—ì„œ ì‹¤í–‰
.\start-dual-gpu.ps1
```

ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ìë™ìœ¼ë¡œ:
1. Pop!_OS Ray Head ì‹œì‘
2. Windows Ray Worker ì—°ê²°
3. ë°±ì—”ë“œ ì„œë²„ ì‹œì‘
4. í”„ë¡ íŠ¸ì—”ë“œ ì‹œì‘
5. ë¸Œë¼ìš°ì € ì˜¤í”ˆ

### 2. Ray í´ëŸ¬ìŠ¤í„° í…ŒìŠ¤íŠ¸
```powershell
# ì—°ê²° í…ŒìŠ¤íŠ¸
.\test-ray-cluster.ps1
```

## ğŸ“‹ ìˆ˜ë™ ì„¤ì • (ë¬¸ì œ í•´ê²°ì‹œ)

### Pop!_OS ì„¤ì •
```bash
# 1. Python í™˜ê²½
cd ~/ArtifexPro
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Ray Head ì‹œì‘
ray stop
ray start --head --port=6379 --dashboard-host=0.0.0.0 --num-gpus=1

# 3. ë°±ì—”ë“œ ì„œë²„
python backend/dual_gpu_model_server.py
```

### Windows ì„¤ì •
```powershell
# 1. Ray Worker ì—°ê²°
pip install ray[default] torch
ray stop
ray start --address=192.168.219.150:6379 --num-gpus=1

# 2. í”„ë¡ íŠ¸ì—”ë“œ
npm install
npm run dev
```

## ğŸ” ëª¨ë‹ˆí„°ë§

### Ray Dashboard
- URL: http://192.168.219.150:8265
- í´ëŸ¬ìŠ¤í„° ìƒíƒœ, GPU ì‚¬ìš©ë¥ , ì‘ì—… í í™•ì¸

### GPU ëª¨ë‹ˆí„°ë§
```bash
# Pop!_OS
watch -n 1 nvidia-smi

# Windows
nvidia-smi -l 1
```

## ğŸ® API ì‚¬ìš©ë²•

### TI2V ìƒì„±
```python
from dual_gpu_client import DualGPUClient

client = DualGPUClient()
result = await client.generate_ti2v(
    image_path="input.jpg",
    prompt="A cinematic scene",
    duration=5.0
)
```

### S2V ìƒì„±
```python
result = await client.generate_s2v(
    audio_path="music.mp3",
    style="cinematic"
)
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| Model | Single GPU | Dual GPU | Speedup |
|-------|------------|----------|---------|
| TI2V-5B | 60s | 35s | 1.7x |
| S2V-14B | 120s | 65s | 1.8x |

## ğŸ› ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Ray ì—°ê²° ì‹¤íŒ¨
```powershell
# ë°©í™”ë²½ í™•ì¸
netsh advfirewall firewall add rule name="Ray" dir=in action=allow protocol=TCP localport=6379,8265,10001

# SSH ì—°ê²° í…ŒìŠ¤íŠ¸
ssh popOS "ray status"
```

### GPU ì¸ì‹ ì•ˆë¨
```python
# GPU í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
python -c "import torch; print(torch.cuda.is_available(), torch.cuda.device_count())"
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
- Qualityë¥¼ "draft"ë¡œ ë‚®ì¶”ê¸°
- Batch size ì¤„ì´ê¸°
- CPU offloading í™œì„±í™”

## ğŸ”„ ì—…ë°ì´íŠ¸

### ëª¨ë¸ ì—…ë°ì´íŠ¸
```bash
# Pop!_OSì—ì„œ
cd ~/ArtifexPro
git pull
python scripts/update_models.py
```

### ì½”ë“œ ë™ê¸°í™”
```powershell
# Windowsì—ì„œ
git pull origin main
npm install
```

## ğŸ“ ê°œë°œ ë…¸íŠ¸

### ë“€ì–¼ GPU íŒŒì´í”„ë¼ì¸
1. **Encoding Phase** (Pop!_OS GPU)
   - Image/Audio ì¸ì½”ë”©
   - íŠ¹ì§• ì¶”ì¶œ
   - ì´ˆê¸° latent ìƒì„±

2. **Generation Phase** (Both GPUs)
   - Diffusion steps ë¶„ì‚°
   - Attention ë³‘ë ¬ ì²˜ë¦¬

3. **Decoding Phase** (Windows GPU)
   - VAE ë””ì½”ë”©
   - í›„ì²˜ë¦¬
   - íŒŒì¼ ì €ì¥

### ìµœì í™” íŒ
- Ray object store í™œìš©ìœ¼ë¡œ GPUê°„ ì „ì†¡ ìµœì†Œí™”
- Pipeline parallelismìœ¼ë¡œ GPU ìœ íœ´ ì‹œê°„ ê°ì†Œ
- Gradient checkpointingìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½

## ğŸ“ ì§€ì›

ë¬¸ì œ ë°œìƒì‹œ:
1. `.\test-ray-cluster.ps1` ì‹¤í–‰
2. Ray Dashboard í™•ì¸
3. ë¡œê·¸ íŒŒì¼ í™•ì¸: `logs/dual_gpu.log`

---
*ArtifexPro Dual GPU System v1.0*