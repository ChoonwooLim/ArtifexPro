"""
ë“€ì–¼ GPU ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
Windowsì™€ Pop!_OS GPUë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í™œìš©
"""

import ray
import torch
import asyncio
from typing import Dict, Any, Optional
import numpy as np
from pathlib import Path
import time
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@ray.remote(num_gpus=1.0)
class ModelShardPop:
    """Pop!_OS GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” ëª¨ë¸ ë¶€ë¶„"""
    
    def __init__(self, model_type: str):
        self.model_type = model_type
        self.device = "cuda:0"
        self.model = None
        
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ (ì‹¤ì œ êµ¬í˜„ì‹œ êµì²´)"""
        logger.info(f"Loading {self.model_type} on Pop!_OS GPU")
        # ì‹¤ì œë¡œëŠ” ì—¬ê¸°ì„œ ëª¨ë¸ ë¡œë“œ
        self.model = f"Mock_{self.model_type}_PopOS"
        return True
    
    def process(self, data: Dict) -> Dict:
        """ì „ë°˜ë¶€ ì²˜ë¦¬"""
        logger.info(f"Processing on Pop!_OS GPU: {self.model_type}")
        time.sleep(1)  # ì‹œë®¬ë ˆì´ì…˜
        
        # ì¤‘ê°„ ê²°ê³¼ ìƒì„±
        return {
            "latents": np.random.randn(1, 4, 64, 64).astype(np.float16),
            "metadata": {"processed_by": "PopOS_GPU"}
        }

@ray.remote(num_gpus=1.0)
class ModelShardWin:
    """Windows GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” ëª¨ë¸ ë¶€ë¶„"""
    
    def __init__(self, model_type: str):
        self.model_type = model_type
        self.device = "cuda:0"
        self.model = None
        
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        logger.info(f"Loading {self.model_type} on Windows GPU")
        self.model = f"Mock_{self.model_type}_Windows"
        return True
    
    def process(self, intermediate: Dict) -> Dict:
        """í›„ë°˜ë¶€ ì²˜ë¦¬"""
        logger.info(f"Processing on Windows GPU: {self.model_type}")
        time.sleep(1)  # ì‹œë®¬ë ˆì´ì…˜
        
        # ìµœì¢… ê²°ê³¼ ìƒì„±
        return {
            "video": f"output_{self.model_type}_{int(time.time())}.mp4",
            "metadata": {
                **intermediate.get("metadata", {}),
                "finalized_by": "Windows_GPU",
                "duration": 5.0
            }
        }

class DualGPUOrchestrator:
    """ë“€ì–¼ GPU ì‘ì—… ì¡°ì •ì"""
    
    def __init__(self):
        self.pop_shard = None
        self.win_shard = None
        self.initialized = False
        
    async def initialize(self, model_type: str = "TI2V"):
        """Ray í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™” ë° ëª¨ë¸ ë¡œë“œ"""
        try:
            # Ray ì—°ê²°
            if not ray.is_initialized():
                ray.init(address='ray://192.168.219.150:10001')
            
            # í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
            resources = ray.cluster_resources()
            logger.info(f"Cluster resources: {resources}")
            
            if resources.get('GPU', 0) < 2:
                raise RuntimeError(f"Need 2 GPUs, found {resources.get('GPU', 0)}")
            
            # ëª¨ë¸ ìƒ¤ë“œ ìƒì„±
            self.pop_shard = ModelShardPop.remote(model_type)
            self.win_shard = ModelShardWin.remote(model_type)
            
            # ë³‘ë ¬ë¡œ ëª¨ë¸ ë¡œë“œ
            pop_ready = self.pop_shard.load_model.remote()
            win_ready = self.win_shard.load_model.remote()
            
            results = ray.get([pop_ready, win_ready])
            if all(results):
                self.initialized = True
                logger.info(f"âœ… Dual GPU {model_type} model ready")
                return True
            
        except Exception as e:
            logger.error(f"âŒ Initialization failed: {e}")
            return False
    
    async def generate_ti2v(
        self,
        image_path: str,
        prompt: str,
        duration: float = 5.0,
        quality: str = "balanced"
    ) -> Dict:
        """TI2V ìƒì„± (ë“€ì–¼ GPU íŒŒì´í”„ë¼ì¸)"""
        
        if not self.initialized:
            await self.initialize("TI2V")
        
        start_time = time.time()
        
        try:
            # Step 1: Pop!_OS GPUì—ì„œ ì¸ì½”ë”© ë° ì´ˆê¸° ì²˜ë¦¬
            logger.info("Step 1: Encoding on Pop!_OS GPU...")
            pop_input = {
                "image_path": image_path,
                "prompt": prompt,
                "duration": duration,
                "quality": quality
            }
            intermediate = ray.get(self.pop_shard.process.remote(pop_input))
            
            # Step 2: Windows GPUì—ì„œ ë””ì½”ë”© ë° ìµœì¢… ì²˜ë¦¬
            logger.info("Step 2: Decoding on Windows GPU...")
            final_result = ray.get(self.win_shard.process.remote(intermediate))
            
            elapsed = time.time() - start_time
            
            return {
                "status": "success",
                "video": final_result["video"],
                "metadata": {
                    **final_result["metadata"],
                    "total_time": elapsed,
                    "gpus_used": 2,
                    "pipeline": "dual_gpu"
                }
            }
            
        except Exception as e:
            logger.error(f"Generation failed: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    async def generate_s2v(
        self,
        audio_path: str,
        style: str = "cinematic",
        duration: Optional[float] = None
    ) -> Dict:
        """S2V ìƒì„± (ë“€ì–¼ GPU íŒŒì´í”„ë¼ì¸)"""
        
        if not self.initialized or self.model_type != "S2V":
            await self.initialize("S2V")
        
        start_time = time.time()
        
        try:
            # Pop!_OSì—ì„œ ì˜¤ë””ì˜¤ ë¶„ì„ ë° íŠ¹ì§• ì¶”ì¶œ
            logger.info("Analyzing audio on Pop!_OS GPU...")
            pop_input = {
                "audio_path": audio_path,
                "style": style,
                "duration": duration
            }
            features = ray.get(self.pop_shard.process.remote(pop_input))
            
            # Windowsì—ì„œ ë¹„ë””ì˜¤ ìƒì„±
            logger.info("Generating video on Windows GPU...")
            final_result = ray.get(self.win_shard.process.remote(features))
            
            elapsed = time.time() - start_time
            
            return {
                "status": "success",
                "video": final_result["video"],
                "metadata": {
                    **final_result["metadata"],
                    "total_time": elapsed,
                    "gpus_used": 2
                }
            }
            
        except Exception as e:
            logger.error(f"S2V generation failed: {e}")
            return {
                "status": "error",
                "message": str(e)
            }
    
    def get_status(self) -> Dict:
        """í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸"""
        if not ray.is_initialized():
            return {"status": "disconnected"}
        
        resources = ray.cluster_resources()
        nodes = ray.nodes()
        
        return {
            "status": "connected" if self.initialized else "ready",
            "gpus": {
                "total": resources.get('GPU', 0),
                "available": ray.available_resources().get('GPU', 0)
            },
            "nodes": [
                {
                    "hostname": node['NodeManagerHostname'],
                    "alive": node['Alive'],
                    "gpu": node['Resources'].get('GPU', 0)
                }
                for node in nodes
            ]
        }
    
    def shutdown(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if ray.is_initialized():
            ray.shutdown()
        logger.info("Orchestrator shutdown complete")

# í…ŒìŠ¤íŠ¸ ì½”ë“œ
async def test_orchestrator():
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í…ŒìŠ¤íŠ¸"""
    orch = DualGPUOrchestrator()
    
    # ì´ˆê¸°í™”
    success = await orch.initialize("TI2V")
    if not success:
        print("âŒ Failed to initialize")
        return
    
    # ìƒíƒœ í™•ì¸
    status = orch.get_status()
    print(f"\nğŸ“Š Cluster Status:")
    print(f"  Status: {status['status']}")
    print(f"  GPUs: {status['gpus']['total']} total, {status['gpus']['available']} available")
    print(f"  Nodes: {len(status['nodes'])}")
    
    # TI2V í…ŒìŠ¤íŠ¸
    print("\nğŸ¬ Testing TI2V generation...")
    result = await orch.generate_ti2v(
        image_path="test.jpg",
        prompt="A beautiful sunset over mountains",
        duration=5.0
    )
    
    if result['status'] == 'success':
        print(f"âœ… Success: {result['video']}")
        print(f"  Time: {result['metadata']['total_time']:.2f}s")
        print(f"  GPUs used: {result['metadata']['gpus_used']}")
    else:
        print(f"âŒ Failed: {result['message']}")
    
    # ì •ë¦¬
    orch.shutdown()

if __name__ == "__main__":
    asyncio.run(test_orchestrator())