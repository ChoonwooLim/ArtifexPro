"""
Wan2.2 Model Status Checker
í˜„ì¬ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
from pathlib import Path
import json

def check_model_files(model_dir):
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ ì²´í¬"""
    model_path = Path(model_dir)
    if not model_path.exists():
        return None
    
    info = {
        "name": model_path.name,
        "path": str(model_path),
        "files": {
            "safetensors": list(model_path.glob("**/*.safetensors")),
            "json": list(model_path.glob("**/*.json")),
            "bin": list(model_path.glob("**/*.bin")),
        },
        "size_gb": sum(f.stat().st_size for f in model_path.rglob("*") if f.is_file()) / (1024**3)
    }
    return info

def main():
    print("=" * 60)
    print("ğŸš€ ArtifexPro - Wan2.2 Model Status")
    print("=" * 60)
    
    models = [
        "Wan2.2-T2V-A14B",
        "Wan2.2-I2V-A14B", 
        "Wan2.2-TI2V-5B",
        "Wan2.2-S2V-14B"
    ]
    
    total_size = 0
    model_status = []
    
    for model in models:
        info = check_model_files(model)
        if info:
            model_status.append(info)
            total_size += info["size_gb"]
            
            print(f"\nâœ… {info['name']}")
            print(f"   Size: {info['size_gb']:.1f} GB")
            print(f"   Safetensors: {len(info['files']['safetensors'])} files")
            print(f"   Config: {len(info['files']['json'])} files")
            
            # ëª¨ë¸ë³„ íŠ¹ì§•
            if "T2V" in model:
                print(f"   Type: Text-to-Video (27B MoE, 14B active)")
                print(f"   VRAM Required: ~80GB")
            elif "I2V" in model:
                print(f"   Type: Image-to-Video (27B MoE)")
                print(f"   VRAM Required: ~80GB")
            elif "TI2V" in model:
                print(f"   Type: Text+Image-to-Video (5B Dense)")
                print(f"   VRAM Required: ~24GB (RTX 4090 ê°€ëŠ¥)")
            elif "S2V" in model:
                print(f"   Type: Speech-to-Video (14B)")
                print(f"   VRAM Required: ~40GB")
        else:
            print(f"\nâŒ {model} - Not found")
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š Total Models: {len(model_status)}/4")
    print(f"ğŸ’¾ Total Size: {total_size:.1f} GB")
    print("=" * 60)
    
    # ì‹¤í–‰ ê¶Œì¥ì‚¬í•­
    print("\nğŸ“ Recommendations:")
    print("1. TI2V-5B ëª¨ë¸ì€ RTX 4090 (24GB VRAM)ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥")
    print("2. T2V/I2V ëª¨ë¸ì€ A100 (80GB) ë˜ëŠ” ë‹¤ì¤‘ GPU í•„ìš”")
    print("3. ëª¨ë¸ íŒŒì¼ì„ Pop!_OSë¡œ ì´ë™ í•„ìš” (GPU ì„œë²„)")
    print("4. NFS/SMBë¡œ Windowsì—ì„œ ë§ˆìš´íŠ¸í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥")

if __name__ == "__main__":
    main()